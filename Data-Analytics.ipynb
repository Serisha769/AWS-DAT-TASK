{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Libraries and Set Up Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import trim\n",
    "import requests\n",
    "from io import StringIO\n",
    "from datetime import datetime\n",
    "\n",
    "# Dynamically generate the current date in YYYY-MM-DD format\n",
    "current_date = datetime.now().strftime('%Y-%m-%d')\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder.appName(\"Data Analytics\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Data from Part 1 (CSV File)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----+------+-----+--------------+\n",
      "|  series_id|year|period|value|footnote_codes|\n",
      "+-----------+----+------+-----+--------------+\n",
      "|PRS30006011|1995|   Q01|  2.6|           NaN|\n",
      "|PRS30006011|1995|   Q02|  2.1|           NaN|\n",
      "|PRS30006011|1995|   Q03|  0.9|           NaN|\n",
      "|PRS30006011|1995|   Q04|  0.1|           NaN|\n",
      "|PRS30006011|1995|   Q05|  1.4|           NaN|\n",
      "+-----------+----+------+-----+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Fetch the data from the URL\n",
    "url = 'https://s3-rearcdataquest.s3.amazonaws.com/pr.data.0.Current'\n",
    "response = requests.get(url)\n",
    "\n",
    "# Convert the data to a Pandas DataFrame\n",
    "data = StringIO(response.text)\n",
    "df_pandas = pd.read_csv(data, sep='\\t')\n",
    "\n",
    "# Convert the Pandas DataFrame to a Spark DataFrame\n",
    "df_spark = spark.createDataFrame(df_pandas)\n",
    "\n",
    "# Clean the column names by stripping any leading/trailing whitespace\n",
    "df_spark = df_spark.select([F.col(col).alias(col.strip()) for col in df_spark.columns])\n",
    "\n",
    "# Trim whitespace from the 'series_id' column\n",
    "df_spark = df_spark.withColumn('series_id', trim(df_spark['series_id']))\n",
    "\n",
    "# Display the first few rows to check\n",
    "df_spark.show(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Data from Part 2 (JSON File)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------+-------+----+----------+-------------+\n",
      "|ID Nation|       Nation|ID Year|Year|Population|  Slug Nation|\n",
      "+---------+-------------+-------+----+----------+-------------+\n",
      "|  01000US|United States|   2022|2022| 331097593|united-states|\n",
      "|  01000US|United States|   2021|2021| 329725481|united-states|\n",
      "|  01000US|United States|   2020|2020| 326569308|united-states|\n",
      "|  01000US|United States|   2019|2019| 324697795|united-states|\n",
      "|  01000US|United States|   2018|2018| 322903030|united-states|\n",
      "+---------+-------------+-------+----+----------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Fetch the JSON data from the provided link\n",
    "url = f'https://s3-rearcdataquest.s3.amazonaws.com/data_{current_date}.json'\n",
    "response = requests.get(url)\n",
    "data = response.json()\n",
    "\n",
    "# Normalize the 'data' part of the JSON\n",
    "df_json = pd.json_normalize(data['data'])\n",
    "\n",
    "df_population_spark = spark.createDataFrame(df_json)\n",
    "\n",
    "# Display the first few rows to check\n",
    "df_population_spark.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate Mean and Standard Deviation of Population (2013-2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Population (2013-2018): 317437383.0\n",
      "Standard Deviation Population (2013-2018): 4257089.541529327\n"
     ]
    }
   ],
   "source": [
    "# Filter the population data for years 2013-2018\n",
    "df_population_filtered = df_population_spark.filter((F.col(\"Year\") >= 2013) & (F.col(\"Year\") <= 2018))\n",
    "\n",
    "# Calculate the mean and standard deviation\n",
    "mean_population = df_population_filtered.agg(F.mean('Population')).collect()[0][0]\n",
    "std_population = df_population_filtered.agg(F.stddev('Population')).collect()[0][0]\n",
    "\n",
    "# Display results\n",
    "print(f\"Mean Population (2013-2018): {mean_population}\")\n",
    "print(f\"Standard Deviation Population (2013-2018): {std_population}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find Best Year for Each series_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----+------------------+\n",
      "|  series_id|year|       total_value|\n",
      "+-----------+----+------------------+\n",
      "|PRS30006011|2022|              20.5|\n",
      "|PRS30006012|2022|17.099999999999998|\n",
      "|PRS30006013|1998|           704.125|\n",
      "|PRS30006021|2010|17.599999999999998|\n",
      "|PRS30006022|2010|              12.5|\n",
      "|PRS30006023|2014|           503.171|\n",
      "|PRS30006031|2022|20.400000000000002|\n",
      "|PRS30006032|2021|17.099999999999998|\n",
      "|PRS30006033|1998|           700.712|\n",
      "|PRS30006061|2022|              38.9|\n",
      "|PRS30006062|2022|              31.7|\n",
      "|PRS30006063|2023| 631.8059999999999|\n",
      "|PRS30006081|2021|              23.4|\n",
      "|PRS30006082|2021|              23.4|\n",
      "|PRS30006083|2021|           112.459|\n",
      "|PRS30006091|2002|43.400000000000006|\n",
      "|PRS30006092|2002|              44.5|\n",
      "|PRS30006093|2011|           520.086|\n",
      "|PRS30006101|2020|              33.5|\n",
      "|PRS30006102|2020|              36.0|\n",
      "+-----------+----+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Group by 'series_id' and 'year', then sum the 'value' column\n",
    "df_grouped = df_spark.groupBy('series_id', 'year').agg(F.sum('value').alias('total_value'))\n",
    "\n",
    "# Find the best year for each 'series_id'\n",
    "df_best_year = df_grouped.groupBy('series_id').agg(F.max(F.struct('total_value', 'year')).alias('max_value_year'))\n",
    "\n",
    "# Select the relevant columns\n",
    "df_best_year = df_best_year.select('series_id', 'max_value_year.year', 'max_value_year.total_value')\n",
    "\n",
    "# Display the final report\n",
    "df_best_year.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate Combined Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----+------+-----+----------+\n",
      "|  series_id|year|period|value|Population|\n",
      "+-----------+----+------+-----+----------+\n",
      "|PRS30006032|2013|   Q01|  0.8| 311536594|\n",
      "|PRS30006032|2014|   Q01| -0.1| 314107084|\n",
      "|PRS30006032|2015|   Q01| -1.6| 316515021|\n",
      "|PRS30006032|2016|   Q01| -1.4| 318558162|\n",
      "|PRS30006032|2017|   Q01|  0.7| 321004407|\n",
      "|PRS30006032|2018|   Q01|  0.4| 322903030|\n",
      "|PRS30006032|2019|   Q01| -1.6| 324697795|\n",
      "|PRS30006032|2020|   Q01| -6.7| 326569308|\n",
      "|PRS30006032|2021|   Q01|  1.2| 329725481|\n",
      "|PRS30006032|2022|   Q01|  5.6| 331097593|\n",
      "+-----------+----+------+-----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display the cleaned DataFrame\n",
    "df_filtered = df_spark.filter((df_spark.series_id == 'PRS30006032') & (df_spark.period == 'Q01'))\n",
    "\n",
    "# # Rename the 'Year' column in the population DataFrame to avoid ambiguity\n",
    "df_population_spark = df_population_spark.withColumnRenamed('Year', 'population_year')\n",
    "\n",
    "# # Join with the population data on 'year'\n",
    "df_final = df_filtered.join(df_population_spark, df_filtered.year == df_population_spark.population_year, 'inner')\n",
    "\n",
    "# # Select and display the relevant columns\n",
    "df_report = df_final.select('series_id', df_filtered.year.alias('year'), 'period', 'value', 'Population')\n",
    "\n",
    "df_report.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
